Norm Bound: 97862.671875
Model Structure: BertForSequenceClassification(
  (bert): BertModel(
    (embeddings): BertEmbeddings(
      (word_embeddings): Embedding(30522, 768, padding_idx=0)
      (position_embeddings): Embedding(512, 768)
      (token_type_embeddings): Embedding(2, 768)
      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
      (dropout): Dropout(p=0.1, inplace=False)
    )
    (encoder): BertEncoder(
      (layer): ModuleList(
        (0-11): 12 x BertLayer(
          (attention): BertAttention(
            (self): BertSelfAttention(
              (query): Linear(in_features=768, out_features=768, bias=True)
              (key): Linear(in_features=768, out_features=768, bias=True)
              (value): Linear(in_features=768, out_features=768, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (output): BertSelfOutput(
              (dense): Linear(in_features=768, out_features=768, bias=True)
              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
          )
          (intermediate): BertIntermediate(
            (dense): Linear(in_features=768, out_features=3072, bias=True)
            (intermediate_act_fn): GELUActivation()
          )
          (output): BertOutput(
            (dense): Linear(in_features=3072, out_features=768, bias=True)
            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)
            (dropout): Dropout(p=0.1, inplace=False)
          )
        )
      )
    )
    (pooler): BertPooler(
      (dense): Linear(in_features=768, out_features=768, bias=True)
      (activation): Tanh()
    )
  )
  (dropout): Dropout(p=0.1, inplace=False)
  (classifier): Linear(in_features=768, out_features=1, bias=True)
)
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
print bias: weights: torch.Size([768])
Per Layer QKV Spectral Norm: [{'Wqk_spectral_norm': [5.352284908294678, 3.261864423751831, 2.1756844520568848, 3.386782169342041, 2.4382381439208984, 2.271352767944336, 2.103235960006714, 2.7038822174072266, 4.299221038818359, 1.5204658508300781, 3.0804178714752197, 2.1938371658325195], 'Wv_spectral_norm': [1.1376709938049316, 1.1140376329421997, 1.097013235092163, 0.9389089345932007, 1.1640889644622803, 1.115019679069519, 1.2574560642242432, 1.0974204540252686, 0.9675320982933044, 1.1525787115097046, 0.8864543437957764, 1.1506288051605225]}, {'Wqk_spectral_norm': [2.479400157928467, 4.575433731079102, 5.310578346252441, 2.425461769104004, 3.9026999473571777, 2.048389434814453, 6.460015773773193, 4.062199592590332, 2.596855401992798, 1.4595496654510498, 3.951561212539673, 2.072615623474121], 'Wv_spectral_norm': [1.2686495780944824, 1.0295143127441406, 1.4319227933883667, 1.4721386432647705, 1.003044843673706, 1.2234458923339844, 1.1239055395126343, 1.4612534046173096, 1.2374824285507202, 1.4044249057769775, 1.2465026378631592, 1.2670657634735107]}, {'Wqk_spectral_norm': [29.8752498626709, 2.466578483581543, 1.523366928100586, 1.523210883140564, 1.7730112075805664, 5.480339527130127, 2.2129225730895996, 2.3829121589660645, 1.7820929288864136, 29.673248291015625, 1.6669700145721436, 2.609942674636841], 'Wv_spectral_norm': [0.7638558149337769, 1.0952205657958984, 1.497760534286499, 1.5806962251663208, 1.1894676685333252, 1.2577754259109497, 1.1917575597763062, 1.2386325597763062, 1.3118088245391846, 0.7772070169448853, 1.2390685081481934, 1.2857074737548828]}, {'Wqk_spectral_norm': [7.265748977661133, 2.248025894165039, 1.6461663246154785, 3.228504180908203, 2.587027072906494, 8.309565544128418, 1.7154889106750488, 1.984070062637329, 1.7254523038864136, 5.237835884094238, 2.040955066680908, 3.109067916870117], 'Wv_spectral_norm': [1.2289663553237915, 1.3376119136810303, 1.6201362609863281, 1.3715403079986572, 1.4722933769226074, 1.1545588970184326, 1.3778390884399414, 1.7600773572921753, 1.211632251739502, 1.169581413269043, 1.0268664360046387, 1.2971314191818237]}, {'Wqk_spectral_norm': [2.1737565994262695, 4.4898576736450195, 2.1101346015930176, 3.976749897003174, 2.1871747970581055, 2.2912051677703857, 1.9985463619232178, 1.5243685245513916, 2.064235210418701, 1.6526463031768799, 2.2570197582244873, 4.053987979888916], 'Wv_spectral_norm': [1.1955764293670654, 1.3761403560638428, 1.773988962173462, 1.4855108261108398, 1.4549833536148071, 1.2012946605682373, 1.2218222618103027, 1.172806739807129, 1.373170018196106, 1.5362000465393066, 1.2994425296783447, 1.3052828311920166]}, {'Wqk_spectral_norm': [1.9790374040603638, 1.944514513015747, 2.025921583175659, 1.924391508102417, 1.5317240953445435, 1.4006500244140625, 1.6788625717163086, 1.6713148355484009, 2.019005298614502, 3.3116092681884766, 2.4799184799194336, 1.7942054271697998], 'Wv_spectral_norm': [1.3864452838897705, 1.2456377744674683, 1.4507694244384766, 1.4344654083251953, 1.4180744886398315, 1.4425685405731201, 1.059098720550537, 1.1765156984329224, 1.6198368072509766, 1.0217299461364746, 1.1565485000610352, 1.1782817840576172]}, {'Wqk_spectral_norm': [1.537683129310608, 1.8733018636703491, 1.7050416469573975, 2.307241201400757, 1.7318522930145264, 1.6667429208755493, 2.205672264099121, 1.7221298217773438, 1.4426441192626953, 1.8353807926177979, 1.6601979732513428, 3.4972667694091797], 'Wv_spectral_norm': [1.4394559860229492, 1.3942999839782715, 1.197433352470398, 1.122863531112671, 1.0791497230529785, 1.0970971584320068, 1.288841962814331, 1.7446377277374268, 1.5854485034942627, 1.0930702686309814, 1.064193606376648, 0.9563988447189331]}, {'Wqk_spectral_norm': [1.8818929195404053, 1.4627859592437744, 2.975125312805176, 1.770932674407959, 3.399834394454956, 1.8486939668655396, 2.1259288787841797, 2.5374464988708496, 1.5960273742675781, 1.7520021200180054, 1.6490721702575684, 2.738647937774658], 'Wv_spectral_norm': [1.4533799886703491, 1.320192813873291, 1.2163652181625366, 1.0746517181396484, 0.8814425468444824, 1.206554889678955, 1.0953450202941895, 1.1766796112060547, 1.3142948150634766, 1.2031216621398926, 1.0350933074951172, 1.0707131624221802]}, {'Wqk_spectral_norm': [2.370293617248535, 1.256226897239685, 2.0010900497436523, 2.161836624145508, 2.195359706878662, 2.8889801502227783, 3.193047523498535, 1.5884883403778076, 1.4878430366516113, 2.133542537689209, 2.1738224029541016, 1.9966329336166382], 'Wv_spectral_norm': [1.2186747789382935, 1.4823362827301025, 1.1116104125976562, 1.1054565906524658, 1.4542088508605957, 1.031773567199707, 1.179277777671814, 1.471709966659546, 1.5722241401672363, 1.3196399211883545, 1.144007682800293, 1.0696396827697754]}, {'Wqk_spectral_norm': [2.012266159057617, 1.7871973514556885, 2.2822279930114746, 2.5477569103240967, 2.6057443618774414, 2.494777202606201, 3.049696207046509, 1.9832289218902588, 1.695042371749878, 2.053302764892578, 2.177032947540283, 1.6552233695983887], 'Wv_spectral_norm': [1.1409835815429688, 1.1437931060791016, 1.1670609712600708, 1.1456162929534912, 1.010146141052246, 1.4731037616729736, 1.2824651002883911, 0.9692022800445557, 1.3881304264068604, 1.0316908359527588, 1.2637521028518677, 1.549980640411377]}, {'Wqk_spectral_norm': [1.386867642402649, 2.0475447177886963, 1.7593681812286377, 1.7427799701690674, 2.2580907344818115, 2.8986141681671143, 2.177516460418701, 2.056065559387207, 1.3233158588409424, 2.326498031616211, 2.5178110599517822, 2.6335620880126953], 'Wv_spectral_norm': [1.5592483282089233, 1.2385499477386475, 1.4891273975372314, 1.5974762439727783, 1.1197460889816284, 1.3294484615325928, 1.1032207012176514, 1.3720738887786865, 1.0832445621490479, 1.2910771369934082, 0.8920153379440308, 1.3989561796188354]}, {'Wqk_spectral_norm': [1.9859986305236816, 2.708582878112793, 1.7245107889175415, 2.536527395248413, 1.8698102235794067, 2.1047229766845703, 1.9901283979415894, 2.2820591926574707, 2.567025661468506, 2.3352513313293457, 2.2810840606689453, 2.4366660118103027], 'Wv_spectral_norm': [1.5221171379089355, 1.5383355617523193, 1.741485357284546, 1.8499102592468262, 1.2951468229293823, 1.2161656618118286, 1.7414430379867554, 1.2937641143798828, 1.529344916343689, 1.5901750326156616, 1.643144130706787, 1.2519567012786865]}]
Evaluating origin:
Final Gelu Layer1:[]; Final Gelu Layer2: []; Final Gelu Layer3: []; Final Softmax Layer1: []; Final Softmax Layer2: []; Final Softmax Layer3: [];
Final Metrics - pearson: 0.8804623790716323, spearman: 0.8763303317439618, Total Loss: 0.5259827123360431
Evaluating best combination 4-4-4-lr15-group:
Final Gelu Layer1:[2, 3, 6, 9]; Final Gelu Layer2: [0, 5, 7, 10]; Final Gelu Layer3: [1, 4, 8, 11]; Final Softmax Layer1: [0, 5, 6, 9]; Final Softmax Layer2: [1, 4, 7, 10]; Final Softmax Layer3: [2, 3, 8, 11];
Final Metrics - pearson: 0.8733584724332597, spearman: 0.8684845042723898, Total Loss: 0.5373712998438389
Evaluating worst combination 4-4-4-lr15-group:
Final Gelu Layer1:[1, 4, 8, 11]; Final Gelu Layer2: [0, 5, 7, 10]; Final Gelu Layer3: [2, 3, 6, 9]; Final Softmax Layer1: [2, 3, 8, 11]; Final Softmax Layer2: [1, 4, 7, 10]; Final Softmax Layer3: [0, 5, 6, 9];
Final Metrics - pearson: 0.865563822737378, spearman: 0.8636978113495689, Total Loss: 0.656872791495729
Evaluating all 1:
Final Gelu Layer1:[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]; Final Gelu Layer2: []; Final Gelu Layer3: []; Final Softmax Layer1: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]; Final Softmax Layer2: []; Final Softmax Layer3: [];
Final Metrics - pearson: 0.8570564459767739, spearman: 0.8528390166208515, Total Loss: 0.622803750665898
Evaluating all 3:
Final Gelu Layer1:[]; Final Gelu Layer2: []; Final Gelu Layer3: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]; Final Softmax Layer1: []; Final Softmax Layer2: []; Final Softmax Layer3: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11];
Final Metrics - pearson: 0.8782042810924066, spearman: 0.8739159243859494, Total Loss: 0.5415714224602314
Evaluating random1 combination 4-4-4-lr15-group:
